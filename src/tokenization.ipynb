{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2445d088-bce5-48ae-8a82-3a5bb45d4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c946e00-0a89-4b53-86f2-de45649afb45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f223645b-c7cc-4879-87fe-6386c8bd0219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/aclImdb/train'\n",
    "\n",
    "data_home = f'{data_dir}/unsup'\n",
    "file_list = os.listdir(data_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64337320-591d-4987-99e2-4274734e85b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in file names\n",
    "files = [f for f in file_list if os.path.isfile(os.path.join(data_home, f))]\n",
    "files_df = pd.DataFrame(files, columns=['File'])\n",
    "\n",
    "# Read in review URLs\n",
    "url_df = pd.read_csv(f'{data_dir}/urls_unsup.txt', header=None)\n",
    "url_df = url_df.rename(columns = {0:'URL'})\n",
    "\n",
    "# Read in IMDb metadata\n",
    "metadata_df = pd.read_csv(f'../data/movie_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1238e70-b46c-4f48-a812-a221b8f71f1b",
   "metadata": {},
   "source": [
    "### Set up LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6801784e-1869-47d9-9489-57e688091d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine reviews with metadata\n",
    "review_metadata_df = url_df.merge(metadata_df, how='left', on='URL')\n",
    "\n",
    "# Combine documents (files) with reviews and metadata\n",
    "LIB = pd.concat([files_df, review_metadata_df], axis=1)\n",
    "\n",
    "# Remove documents with no metadata\n",
    "LIB = LIB[LIB['ID'].notnull()].drop(columns=['Error'])\n",
    "\n",
    "LIB['Genre'] = LIB.Genres.str.split(',').str[0]\n",
    "\n",
    "LIB['Genre 2'] = LIB.Genres.str.split(',').str[1]\n",
    "\n",
    "LIB['Genre 3'] = LIB.Genres.str.split(',').str[2]\n",
    "\n",
    "# Split Genres and store in cols\n",
    "genres_df = LIB.copy()\n",
    "genres_df['Genres'] = genres_df['Genres'].str.split(', ')\n",
    "genres_exploded = genres_df.explode('Genres')\n",
    "\n",
    "# Create the one-hot encoding\n",
    "genre_dummies = pd.get_dummies(genres_exploded['Genres'], prefix='', prefix_sep='')\n",
    "\n",
    "# Combine the dummies with original data by grouping back to original rows\n",
    "genre_dummies = genre_dummies.groupby(level=0).max()\n",
    "\n",
    "# Join the original DataFrame with the genre columns\n",
    "LIB = pd.concat([LIB, genre_dummies], axis=1).reset_index(drop=True)\n",
    "\n",
    "# Sample 5,000 reviews\n",
    "LIB = LIB.sample(5000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Set index name\n",
    "LIB.index.name = 'review_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fb5bd1-6710-4b44-9f7a-50f5fdbd785e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Action         1044\n",
       "Adult             8\n",
       "Adventure       770\n",
       "Animation       193\n",
       "Biography       179\n",
       "Comedy         1681\n",
       "Crime           857\n",
       "Documentary     140\n",
       "Drama          2473\n",
       "Family          352\n",
       "Fantasy         563\n",
       "Film-Noir        63\n",
       "Game-Show        11\n",
       "History         162\n",
       "Horror         1028\n",
       "Music           177\n",
       "Musical         137\n",
       "Mystery         578\n",
       "News              7\n",
       "Reality-TV       21\n",
       "Romance         972\n",
       "Sci-Fi          693\n",
       "Short            82\n",
       "Sport            98\n",
       "Talk-Show        12\n",
       "Thriller       1421\n",
       "War             246\n",
       "Western         133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_cols = LIB.select_dtypes(include='bool')  # Select only boolean columns\n",
    "bool_cols.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff102db-8ca6-4167-95f4-2041e1d51592",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB.to_csv('LIB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19cae23-0e96-42d6-9f5a-208186594863",
   "metadata": {},
   "source": [
    "### Set up TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947490de-2680-4af9-9dfc-75f0f04af028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OHCO = ['review_id', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f7a90-0993-4bd2-88ee-3fbd3089d1c2",
   "metadata": {},
   "source": [
    "#### Read PARAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6ead82-7707-402e-b40a-107185667da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List to store the raw content of each file\n",
    "file_contents = []\n",
    "\n",
    "files = [file for file in LIB.File]\n",
    "\n",
    "# Initialize a counter for the review_id\n",
    "review_id = 0\n",
    "\n",
    "# Loop through each file\n",
    "for file in files:\n",
    "    \n",
    "    file_path = data_home + '/' + file\n",
    "    \n",
    "    # Read the file content\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        file_content = f.read()  # Read the entire file as a string\n",
    "    \n",
    "    # Replace <br /> tags with newline characters\n",
    "    file_content = file_content.replace('<br />', '\\n')\n",
    "    \n",
    "    # Split content by newlines to create individual lines\n",
    "    lines = file_content.splitlines()\n",
    "    \n",
    "    # Create DataFrame with each line as a row\n",
    "    df = pd.DataFrame(lines, columns=['para_str'])\n",
    "    \n",
    "    df = df[~df['para_str'].str.match(r'^\\s*$')]\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Set 'line_num' as the index for each file's DataFrame\n",
    "    df.index.name = 'para_num'\n",
    "    \n",
    "    # Reset the index to make 'line_num' a regular column\n",
    "    df = df.reset_index('para_num')\n",
    "    \n",
    "    # Add a 'review_id' for each file (constant for each file)\n",
    "    df['review_id'] = review_id\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    file_contents.append(df)\n",
    "    \n",
    "    # Increment review_id for the next file\n",
    "    review_id += 1\n",
    "\n",
    "# Concatenate all file contents into one DataFrame\n",
    "PARAS = pd.concat(file_contents)\n",
    "\n",
    "# Set MultiIndex with 'review_id' and 'line_num'\n",
    "PARAS.set_index(OHCO[0:2], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e2550da-dd21-4aae-bfae-5ab4176ee303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>This is a mildly enjoyable flick which attempt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In trying to be serious and political the film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>On the whole, this was a pretty good, pretty f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>I cannot wait to see the goofs start on this h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I also choked on my drink when a certain perso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             para_str\n",
       "review_id para_num                                                   \n",
       "0         0         This is a mildly enjoyable flick which attempt...\n",
       "          1         In trying to be serious and political the film...\n",
       "1         0         On the whole, this was a pretty good, pretty f...\n",
       "2         0         I cannot wait to see the goofs start on this h...\n",
       "          1         I also choked on my drink when a certain perso..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffeaba5-5936-4c07-aaa4-07252b142ede",
   "metadata": {},
   "source": [
    "#### Read SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0614cfb6-3efb-4331-95df-43cfe001aad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTS = PARAS.para_str.apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame('sent_str')\n",
    "\n",
    "SENTS.index.names = OHCO[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8131fec-54f4-431f-b342-0b23b568dd81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>This is a mildly enjoyable flick which attempt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is mainly due to the exceedingly annoying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OK in this case it is not taken too far but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>In trying to be serious and political the film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And the there's the plot holes, oh my god, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      sent_str\n",
       "review_id para_num sent_num                                                   \n",
       "0         0        0         This is a mildly enjoyable flick which attempt...\n",
       "                   1         This is mainly due to the exceedingly annoying...\n",
       "                   2         OK in this case it is not taken too far but it...\n",
       "          1        0         In trying to be serious and political the film...\n",
       "                   1         And the there's the plot holes, oh my god, the..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5d63e-04a1-4e12-ac0f-3b1586b59422",
   "metadata": {},
   "source": [
    "#### Split into TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8faf695-15af-4d77-86ad-4771e44f97cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKENS = SENTS.sent_str\\\n",
    "            .apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x))))\\\n",
    "            .stack()\\\n",
    "            .to_frame('pos_tuple')\n",
    "\n",
    "TOKENS['pos'] = TOKENS.pos_tuple.apply(lambda x: x[1])\n",
    "TOKENS['pos_group'] = TOKENS.pos.str[:2]\n",
    "TOKENS['token_str'] = TOKENS.pos_tuple.apply(lambda x: x[0])\n",
    "TOKENS['term_str'] = TOKENS.token_str.str.lower().str.replace(r\"\\W+\", \"\", regex=True)\n",
    "\n",
    "TOKENS.index.names = OHCO[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a979da7b-8369-4bdd-bd27-4e133b9f2541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_group</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>27</th>\n",
       "      <td>(problem, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>problem</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>23</th>\n",
       "      <td>(., .)</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <th>5</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <td>(by, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>21</th>\n",
       "      <td>(make, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>make</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>24</th>\n",
       "      <td>(Henry, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>Henry</td>\n",
       "      <td>henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>27</th>\n",
       "      <td>(,, ,)</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>11</th>\n",
       "      <td>(but, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>but</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <td>(rented, VBN)</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>rented</td>\n",
       "      <td>rented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>32</th>\n",
       "      <td>(like, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <td>(is, VBZ)</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VB</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pos_tuple  pos pos_group token_str  \\\n",
       "review_id para_num sent_num token_num                                           \n",
       "374       2        1        27         (problem, NN)   NN        NN   problem   \n",
       "1840      3        1        23                (., .)    .         .         .   \n",
       "1335      5        2        3               (by, IN)   IN        IN        by   \n",
       "2814      0        1        21            (make, VB)   VB        VB      make   \n",
       "3039      2        0        24          (Henry, NNP)  NNP        NN     Henry   \n",
       "4489      4        2        27                (,, ,)    ,         ,         ,   \n",
       "1636      0        2        11             (but, CC)   CC        CC       but   \n",
       "2824      0        1        4          (rented, VBN)  VBN        VB    rented   \n",
       "1256      0        4        32            (like, IN)   IN        IN      like   \n",
       "1046      0        6        7              (is, VBZ)  VBZ        VB        is   \n",
       "\n",
       "                                      term_str  \n",
       "review_id para_num sent_num token_num           \n",
       "374       2        1        27         problem  \n",
       "1840      3        1        23                  \n",
       "1335      5        2        3               by  \n",
       "2814      0        1        21            make  \n",
       "3039      2        0        24           henry  \n",
       "4489      4        2        27                  \n",
       "1636      0        2        11             but  \n",
       "2824      0        1        4           rented  \n",
       "1256      0        4        32            like  \n",
       "1046      0        6        7               is  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa487469-6297-4000-9736-010d7d6eebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS.to_csv('TOKENS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665e6b5-ab86-4dc9-bb44-82e66d25e4ca",
   "metadata": {},
   "source": [
    "#### Get VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca6dd5a-200b-4e97-99c2-da9db42f587d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB = TOKENS.term_str.value_counts().to_frame('n')\n",
    "VOCAB.index.name = 'term_str'\n",
    "\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)\n",
    "\n",
    "# Define stopwords\n",
    "sw = pd.DataFrame({'stop': 1}, index=nltk.corpus.stopwords.words('english'))\n",
    "sw.index.name = 'term_str'\n",
    "\n",
    "# Create Porter stems\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['porter_stem'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), axis=1)\n",
    "\n",
    "# Create maximum POS fields\n",
    "VOCAB['max_pos'] = TOKENS.groupby(['term_str', 'pos']).size().unstack(fill_value=0).idxmax(axis=1)\n",
    "VOCAB['max_pos_group'] = TOKENS.groupby(['term_str', 'pos_group']).size().unstack(fill_value=0).idxmax(axis=1)\n",
    "\n",
    "# Join vocab to stop words\n",
    "if 'stop' not in VOCAB.columns:\n",
    "    VOCAB = VOCAB.join(sw)\n",
    "    VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ddcbd7-f04b-4e02-9f3b-9290fc53d5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>porter_stem</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>158602</td>\n",
       "      <td>1.193317e-01</td>\n",
       "      <td>3.066951</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>66897</td>\n",
       "      <td>5.033312e-02</td>\n",
       "      <td>4.312348</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>32261</td>\n",
       "      <td>2.427309e-02</td>\n",
       "      <td>5.364498</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>32120</td>\n",
       "      <td>2.416700e-02</td>\n",
       "      <td>5.370818</td>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>28482</td>\n",
       "      <td>2.142978e-02</td>\n",
       "      <td>5.544239</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metalsongs</th>\n",
       "      <td>1</td>\n",
       "      <td>7.523973e-07</td>\n",
       "      <td>20.342002</td>\n",
       "      <td>metalsong</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goatees</th>\n",
       "      <td>1</td>\n",
       "      <td>7.523973e-07</td>\n",
       "      <td>20.342002</td>\n",
       "      <td>goate</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metalpurists</th>\n",
       "      <td>1</td>\n",
       "      <td>7.523973e-07</td>\n",
       "      <td>20.342002</td>\n",
       "      <td>metalpurist</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sternn</th>\n",
       "      <td>1</td>\n",
       "      <td>7.523973e-07</td>\n",
       "      <td>20.342002</td>\n",
       "      <td>sternn</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telegraphed</th>\n",
       "      <td>1</td>\n",
       "      <td>7.523973e-07</td>\n",
       "      <td>20.342002</td>\n",
       "      <td>telegraph</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44495 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   n             p          i  porter_stem max_pos  \\\n",
       "term_str                                                             \n",
       "              158602  1.193317e-01   3.066951                    .   \n",
       "the            66897  5.033312e-02   4.312348          the      DT   \n",
       "and            32261  2.427309e-02   5.364498          and      CC   \n",
       "a              32120  2.416700e-02   5.370818            a      DT   \n",
       "of             28482  2.142978e-02   5.544239           of      IN   \n",
       "...              ...           ...        ...          ...     ...   \n",
       "metalsongs         1  7.523973e-07  20.342002    metalsong     NNS   \n",
       "goatees            1  7.523973e-07  20.342002        goate     NNS   \n",
       "metalpurists       1  7.523973e-07  20.342002  metalpurist     NNS   \n",
       "sternn             1  7.523973e-07  20.342002       sternn     NNP   \n",
       "telegraphed        1  7.523973e-07  20.342002    telegraph     VBN   \n",
       "\n",
       "             max_pos_group  stop  \n",
       "term_str                          \n",
       "                         .     0  \n",
       "the                     DT     1  \n",
       "and                     CC     1  \n",
       "a                       DT     1  \n",
       "of                      IN     1  \n",
       "...                    ...   ...  \n",
       "metalsongs              NN     0  \n",
       "goatees                 NN     0  \n",
       "metalpurists            NN     0  \n",
       "sternn                  NN     0  \n",
       "telegraphed             VB     0  \n",
       "\n",
       "[44495 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab154d1f-5c62-42d8-91a4-bd61c31daa6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB.to_csv('VOCAB.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
