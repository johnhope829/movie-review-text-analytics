{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979923b5-0493-4768-ad1a-06db54f0bc7a",
   "metadata": {},
   "source": [
    "# Final Project Notebook\n",
    "\n",
    "DS 5001 Text as Data | Spring 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046f57f-12ed-4259-be3d-60cb67b8d044",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "- Full Name: John Hope\n",
    "- Userid: jah9kqn\n",
    "- GitHub Repo URL: https://github.com/johnhope829/movie-review-text-analytics\n",
    "- UVA Box URL: https://virginia.box.com/s/zf7r4jxkvc2udvrchmwh2efqw5g8lm13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acd11d-eb04-4bcc-b115-f205f367de49",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The goal of the final project is for you to create a **digital analytical edition** of a corpus using the tools, practices, and perspectives youâ€™ve learning in this course. You will select a corpus that has already been digitized and transcribed, parse that into an F-compliant set of tables, and then generate and visualize the results of a series of fitted models. You will also draw some tentative conclusions regarding the linguistic, cultural, psychological, or historical features represented by your corpus. The point of the exercise is to have you work with a corpus through the entire pipeline from ingestion to interpretation. \n",
    "\n",
    "Specifically, you will acquire a collection of long-form texts and perform the following operations:\n",
    "\n",
    "- **Convert** the collection from their source formats (F0) into a set of tables that conform to the Standard Text Analytic Data Model (F2).\n",
    "- **Annotate** these tables with statistical and linguistic features using NLP libraries such as NLTK (F3).\n",
    "- **Produce** a vector representation of the corpus to generate TFIDF values to add to the TOKEN (aka CORPUS) and VOCAB tables (F4).\n",
    "- **Model** the annotated and vectorized model with tables and features derived from the application of unsupervised methods, including PCA, LDA, and word2vec (F5).\n",
    "- **Explore** your results using statistical and visual methods.\n",
    "- **Present** conclusions about patterns observed in the corpus by means of these operations.\n",
    "\n",
    "When you are finished, you will make the results of your work available in GitHub (for code) and UVA Box (for data). You will submit to Gradescope (via Canvas) a PDF version of a Jupyter notebook that contains the information listed below.\n",
    "\n",
    "# Some Details\n",
    "\n",
    "- Please fill out your answers in each task below by editing the markdown cell. \n",
    "- Replace text that asks you to insert something with the thing, i.e. replace `(INSERT IMAGE HERE)` with an image element, e.g. `![](image.png)`.\n",
    "- For URLs, just paste the raw URL directly into the text area. Don't worry about providing link labels using `[label](link)`.\n",
    "- Please do not alter the structure of the document or cell, i.e. the bulleted lists. \n",
    "- You may add explanatory paragraphs below the bulleted lists.\n",
    "- Please name your tables as they are named in each task below.\n",
    "- Tasks are indicated by headers with point values in parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b6d68-e039-4612-858b-29510eeb5365",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0889de-cd53-4aa5-80b2-a2a39060776a",
   "metadata": {},
   "source": [
    "## Source Description (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e395a-4b0b-4ba3-9112-80c733998dbe",
   "metadata": {},
   "source": [
    "Provide a brief description of your source material, including its provenance and content. Tell us where you found it and what kind of content it contains.\n",
    "\n",
    "The data for this project is sourced from the Large Movie Review Dataset, and contains IMDb movie reviews. The dataset contains 50,000 movie reviews across over 7,000 movies. Of the 50,000 reviews, the distribution is balanced among positive and negative reviews, with 25,000 each. More informatio to the dataset homepage can be found [here](https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "The data in the set contains the review texts, and URLs pointing to the IMDb page. Because the dataset doesn't contain information regarding the movies/shows the reviews are about, this information had to be collected seperately. For these purposes, the [IMDbPy](https://pypi.org/project/IMDbPY/) (now cinemagoer) package was used to gather movie/show metadata, including titles, release years and genres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b507c1-6dc2-44f7-b74c-790d84a48e8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Features (1)\n",
    "\n",
    "Add values for the following items. (Do this for all following bulleted lists.)\n",
    "\n",
    "- Source URL: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "- UVA Box URL: https://virginia.box.com/s/iajc1o8j068wyyb8dn88g0febmctrjkg\n",
    "- Number of raw documents: 50,000\n",
    "- Total size of raw documents (e.g. in MB): ~(63.4 MB)\n",
    "- File format(s), e.g. XML, plaintext, etc.: plaintext (.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e81b1-9f70-47b5-bb25-49be4e76b98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Document Structure (1)\n",
    "\n",
    "Provide a brief description of the internal structure of each document. That, describe the typical elements found in document and their relation to each other. For example, a corpus of letters might be described as having a date, an addressee, a salutation, a set of content paragraphs, and closing. If they are various structures, state that.\n",
    "\n",
    "Each document consists of an indivudal movie/show review. They typically only contain one or multiple content paragraphs providing a hollistic review of their viewing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec4c9f-e101-46fe-ac59-a35a1b148a4b",
   "metadata": {},
   "source": [
    "# Parsed and Annotated Data\n",
    "\n",
    "Parse the raw data into the three core tables of your addition: the `LIB`, `CORPUS`, and `VOCAB` tables.\n",
    "\n",
    "These tables will be stored as CSV files with header rows.\n",
    "\n",
    "You may consider using `|` as a delimitter.\n",
    "\n",
    "Provide the following information for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d05ce4-ac5c-43ea-a07b-c4626338f80e",
   "metadata": {},
   "source": [
    "## LIB (2)\n",
    "\n",
    "The source documents the corpus comprises. These may be books, plays, newspaper articles, abstracts, blog posts, etc. \n",
    "\n",
    "Note that these are *not* documents in the sense used to describe a bag-of-words representation of a text, e.g. chapter.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/lg8kxpizyplaes1s6qw1juankksvm9lb\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/tokenization.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Number of observations: 5,000 (subset from original 50,000)\n",
    "- List of features, including at least three that may be used for model summarization (e.g. date, author, etc.): Title, Release Year, Rating, Genre\n",
    "- Average length of each document in characters: 1316"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304204a5-00be-46ad-b98b-0d10a9c8ca4b",
   "metadata": {},
   "source": [
    "## CORPUS (2)\n",
    "\n",
    "The sequence of word tokens in the corpus, indexed by their location in the corpus and document structures.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/jc3e5nm006rrueq6xuv8ugcstyedbdhu\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/tokenization.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Number of observations Between (should be >= 500,000 and <= 2,000,000 observations.): 1,329,085\n",
    "- OHCO Structure (as delimitted column names): [`review_id`, `para_num`, `sent_num`, `token_num`]\n",
    "- Columns (as delimitted column names): [`pos_tuple`, `pos`, `pos_group`, `token_str`, `term_str`]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3214e-e6dd-42d6-842f-555d0058986e",
   "metadata": {},
   "source": [
    "## VOCAB (2)\n",
    "\n",
    "The unique word types (terms) in the corpus.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/xi7nco98p5py46mzhon7aan78s54ysw1\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/tokenization.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Number of observations: 44,495\n",
    "- Columns (as delimitted names, including `n`, `p`', `i`, `dfidf`, `porter_stem`, `max_pos` and `max_pos_group`, `stop`): [`n`, `p`, `i`, `porter_stem`, `max_pos`, `max_pos_group`, `stop`, `df`,`idf`, `dfidf`]\n",
    "- Note: Your VOCAB may contain ngrams. If so, add a feature for `ngram_length`.\n",
    "- List the top 20 significant words in the corpus by DFIDF.\n",
    "\n",
    "1. good\n",
    "2. more\n",
    "3. some\n",
    "4. when\n",
    "5. what\n",
    "6. would\n",
    "7. up\n",
    "8. very\n",
    "9. only\n",
    "10. if\n",
    "11. has\n",
    "12. out\n",
    "13. he\n",
    "14. time\n",
    "15. or\n",
    "16. can\n",
    "17. just\n",
    "18. see\n",
    "19. even\n",
    "20. no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dabdc-baae-4408-95bc-2f735824d59b",
   "metadata": {},
   "source": [
    "# Derived Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f2ef9c-1cb5-41e8-a5ee-1e37428b4539",
   "metadata": {},
   "source": [
    "## BOW (3)\n",
    "\n",
    "A bag-of-words representation of the CORPUS.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/gteuhpfex0axitl43zi4p8y4nqtu24oa\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/bow_tfidf.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Bag (expressed in terms of OHCO levels): `review_id`\n",
    "- Number of observations: 694,927\n",
    "- Columns (as delimitted names): [`n`,`tf`,`tfidf`]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29890d2f-bf96-43ad-8d08-792393830163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DTM (3)\n",
    "\n",
    "A represenation of the BOW as a sparse count matrix.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/6eos5hq6a5ga66x5ihbgikqyajzx0x3x\n",
    "- UVA Box URL of BOW used to generate (if applicable): \n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/bow_tfidf.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Bag (expressed in terms of OHCO levels): `review_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b4774-7c76-401d-a9de-2704f28a0821",
   "metadata": {},
   "source": [
    "## TFIDF (3)\n",
    "\n",
    "A Document-Term matrix with TFIDF values.\n",
    "\n",
    "- UVA Box URL:https://virginia.box.com/s/t0hisy338zygh2wl8l7ymdrhf2q5luh9\n",
    "- UVA Box URL of DTM or BOW used to create:\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/bow_tfidf.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Description of TFIDIF formula ($\\LaTeX$ OK): \n",
    "\n",
    "$$\n",
    "TF(t,d) = \\frac{\\text{number of times } t \\text{ appears in } d}{\\text{total number of terms in } d}\n",
    "$$\n",
    "\n",
    "$$\n",
    "IDF(t) = \\log \\left( \\frac{N}{1 + df} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "TFIDF(t,d) = TF(t,d) \\times IDF(t)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34f5ca-5361-4701-b9dd-9da66859b40b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduced and Normalized TFIDF_L2 (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c548dd2-f692-4365-936c-39c84df79b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "A Document-Term matrix with L2 normalized TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/srkx21qs5q0b7jw29dwk8vjj66kw16ou\n",
    "- UVA Box URL of source TFIDF table:\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/bow_tfidf.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Number of features (i.e. significant words): 5000\n",
    "- Principle of significant word selection: Top 5000 nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50da94-af36-4e8d-b1a7-24dbcf431880",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df79264-dd93-4199-be38-db31579b7ce8",
   "metadata": {},
   "source": [
    "## PCA Components (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/aavwkqsrs562plackefcexbqn4ircqx5\n",
    "- UVA Box URL of the source TFIDF_L2 table:\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/pca.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Number of components: 10\n",
    "- Library used to generate: Scikit-learn\n",
    "- Top 5 positive terms for first component: [show, episode, series, episodes, tv]\n",
    "- Top 5 negative terms for second component: [movie, movies, show, horror, acting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adc882-cbce-4d24-9923-5d36ac609f43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA DCM (4)\n",
    "\n",
    "The document-component matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/z0osarw0z9gu0j987q1k7m1kblpmw4d1\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/pca.ipynb\n",
    "- Delimitter: comma (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd2a4a-7f2f-4259-a5c4-063168cb1b14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA Loadings (4)\n",
    "\n",
    "The component-term matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/0qcnm5ee3djsrj06fuj71hxdm1699fp8\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/pca.ipynb\n",
    "- Delimitter: comma (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5bb6e2-9d4c-421f-944a-fd5913027bc5",
   "metadata": {},
   "source": [
    "## PCA Visualization 1 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the first two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "![](../figures/pca_1.png)\n",
    "\n",
    "![](../figures/pca_2.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the first component:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c696627-4d75-40c4-b045-62ccd85c5002",
   "metadata": {},
   "source": [
    "Looking at the visuals above, there appears to be a lot of similarity in the first comonent across genres, but there are a few differences we can take away. Looking at the bar plot, most of the genres have a very similar median, but what differentiates them is the wideness of their ranges. More popular genres, like Comedy, Action, and Drama, have much wider ranges than less popular genres, like Game-Show, Western, and Adult, which makes sense as the more popular genres have many more documents. The same is true for word groups, where nouns have much larger ranges than adjectives and verbs, likely due to the higher presence in the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb54565-7669-4a2f-90b2-a4c283277c02",
   "metadata": {},
   "source": [
    "## PCA Visualization 2 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the second two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "![](../figures/pca_3.png)\n",
    "\n",
    "![](../figures/pca_4.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the second component:\n",
    "\n",
    "Looking at the visuals above, similar to the last part, there appears to be a lot of similarity in the second comonent across genres. Looking at the bar plot, most of the genres have a very similar median, but what differentiates them is the wideness of their ranges. The key difference noted here is the huge increase in range specifically for the Game-Show genre, which had a very narrow range in the first component. The same pattern, as in the last part, is true for word groups, where nouns have much larger ranges than adjectives and verbs, likely due to the higher presence in the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee23b2-25d1-4226-bf31-1607e5ed4677",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA TOPIC (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/jxmskmo5yiwb5528frkaj9ghhmfbel8l\n",
    "- UVA Box URL of count matrix used to create:\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/lda.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Libary used to compute: Scikit-learn\n",
    "- A description of any filtering, e.g. POS (Nouns and Verbs only): nouns and plural nouns\n",
    "- Number of components: 20\n",
    "- Any other parameters used:\n",
    "  - n_terms = 5000\n",
    "  - n_topics = 20\n",
    "  - max_iter = 5\n",
    "  - n_top_terms = 7\n",
    "  - ngram_range = (1, 2)\n",
    "- Top 5 words and best-guess labels for topic five topics by mean document weight:\n",
    "  - T00: movie time way director story (Label: Game-Show)\n",
    "  - T01: film films movie plot characters (Label: News)\n",
    "  - T02: time family people story life (Label: Documentary)\n",
    "  - T03: game movie life time scene (Label: Film-Noir)\n",
    "  - T04: movie seat character card cat (Label: Western)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518d520-4a5c-48fa-836d-f8ea3e3c2f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA THETA (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/clrd4vie6zxwg6rs8ej6fzi4nc4p2f3f\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/lda.ipynb\n",
    "- Delimitter: comma (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8808b30-64f4-4249-95d5-d7c0925ce432",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA PHI (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/spwpt4c0o0nab52yexlblxcti341c56o\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/lda.ipynb\n",
    "- Delimitter: comma (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e404bf-8a2a-4eb4-ba89-0c708c8f359d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LDA + PCA Visualization (4)\n",
    "\n",
    "Apply PCA to the PHI table and plot the topics in the space opened by the first two components.\n",
    "\n",
    "Size the points based on the mean document weight of each topic (using the THETA table).\n",
    "\n",
    "Color the points basd on a metadata feature from the LIB table.\n",
    "\n",
    "Provide a brief interpretation of what you see.\n",
    "\n",
    "![](../figures/lda_pca.png)\n",
    "\n",
    "Looking at the above visal, there appears to be a few interesting patterns.\n",
    "\n",
    "The first point being that the size of the points tend to increase as the value for the second component (1) decreases. This indicates that these more dominant topics may be less distinctive or more general.\n",
    "\n",
    "Additionally, another interesting point is that the all the genres assigned to the topics are less popular. None of the topics are pointed to the most popular genres (action, comedy, horror, drama, crime). This indicates that documents representing the popular genres don't have very distinctive topic distributions, whereas more niche genres do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1f327-a386-476a-8d94-2ab7a63afa7a",
   "metadata": {},
   "source": [
    "## Sentiment VOCAB_SENT (4)\n",
    "\n",
    "Sentiment values associated with a subset of the VOCAB from a curated sentiment lexicon.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/qfkl3o3aclj1jvaf592wydjip148hyft\n",
    "- UVA Box URL for source lexicon:\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/sentiment_analysis.ipynb\n",
    "- Delimitter: comma (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a9d67-1560-4be9-b82a-b99a60b5c93e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment BOW_SENT (4)\n",
    "\n",
    "Sentiment values from VOCAB_SENT mapped onto BOW.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/adhc8c42gcnbr9fa7y327j15gx07osqg\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/sentiment_analysis.ipynb\n",
    "- Delimitter: comma (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee6837-b12e-453d-96c1-59eaa4b28883",
   "metadata": {},
   "source": [
    "## Sentiment DOC_SENT (4)\n",
    "\n",
    "Computed sentiment per bag computed from BOW_SENT.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/60w4v2k59j3jp4wpnhlpgfq6yqhyi02b\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/sentiment_analysis.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Document bag expressed in terms of OHCO levels: `review_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cba13-e60a-4940-a06d-02479f002c3c",
   "metadata": {},
   "source": [
    "## Sentiment Plot (4)\n",
    "\n",
    "Plot sentiment over some metric space, such as time.\n",
    "\n",
    "If you don't have a metric metadata features, plot sentiment over a feature of your choice.\n",
    "\n",
    "You may use a bar chart or a line graph.\n",
    "\n",
    "![](../figures/sentiment_genre.png)\n",
    "\n",
    "![](../figures/sentiment_year.png)\n",
    "\n",
    "From the visuals above, we can see interesting trends in sentiment across genre and time. Looking at the bar plot for genre, we see that genres like News, Reality-TV, and Family are among the most positive average sentiments, whereas Sports and Game-Show are the two lowest/most negative. These seem to be plausible, as viewers are likely more receptive to informative and grounded stories like the positive genres, whereas sports and game-shows promote competition, which may sway viewers to be more harsh. However, all of these genres do have a limited representation in the corpus, so these results may not be very generalizable.\n",
    "\n",
    "Looking at sentiment over time, there doesn't appear to be any major changes, maybe slight increases in sentiment after the 1980's, except the line appears to converge starting in the 1960's which is likely due to simply having more films/shows in these periods represented in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d2316-317b-4d95-a804-aff98242e411",
   "metadata": {},
   "source": [
    "## VOCAB_W2V (4)\n",
    "\n",
    "A table of word2vec features associated with terms in the VOCAB table.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/dqwdmdb4fhfqg8tsloe7ikavh3inlx9v\n",
    "- GitHub URL for notebook used to create: https://github.com/johnhope829/movie-review-text-analytics/blob/main/src/word2vec.ipynb\n",
    "- Delimitter: comma (.csv)\n",
    "- Document bag expressed in terms of OHCO levels: `review_id`\n",
    "- Number of features generated: 256\n",
    "- The library used to generate the embeddings: Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c1974-047b-4285-9f4d-7f3314f39542",
   "metadata": {},
   "source": [
    "## Word2vec tSNE Plot (4)\n",
    "\n",
    "Plot word embedding featues in two-dimensions using t-SNE.\n",
    "\n",
    "Describe a cluster in the plot that captures your attention.\n",
    "\n",
    "![](../figures/word2vec.png)\n",
    "\n",
    "Looking at the visual above there appears to be a few clusters. One interesting one is the group of verbs (purple) at around (-60, 10) on the graph. Many of the verbs are dealing with the viewership of the associated films/shows, including words like saw, seen, viewed, liked, enjoyed. Clearly, the embedding model was able to detect well the semantic similarity of these words within the context of these reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75878341-7fe8-4e22-b908-36029f9818e8",
   "metadata": {},
   "source": [
    "# Riffs\n",
    "\n",
    "Provde at least three visualizations that combine the preceding model data in interesting ways.\n",
    "\n",
    "These should provide insight into how features in the LIB table are related. \n",
    "\n",
    "The nature of this relationship is left open to you -- it may be correlation, or mutual information, or something less well defined. \n",
    "\n",
    "In doing so, consider the following visualization types:\n",
    "\n",
    "- Hierarchical cluster diagrams\n",
    "- Heatmaps\n",
    "- Scatter plots\n",
    "- KDE plots\n",
    "- Dispersion plots\n",
    "- t-SNE plots\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62acf1-6bb0-45d0-aed2-863b285f8cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 1 (5)\n",
    "\n",
    "![](../figures/genre_decade_sentiment.png)\n",
    "\n",
    "The above heatmap shows the relationship between average sentiment across genres and decades. While there appears to be relatively neutral sentiments for the majority of points here, we can see moderate increases in sentiment scores for genres like Comedy, Action, and Drama throughout time, while genres like Horror and Musical show more fluctuating or negative sentiments over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155a072-02b3-4aa8-b9f1-e43a59e9a85d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 2 (5)\n",
    "\n",
    "![](../figures/sentiment_by_rating.png)\n",
    "\n",
    "An interesting takeaway from this visual is there being that there is a clear bimodal distribution, with the lowest rated and highest rated movies having the highest average sentiments, though the sample size of these movies is limited compared to the other bins. This could indicate that very high rated movies are spoken well of, and that the lowest rated movies may have high sentiment for nostalgia or how comically bad the movies/shows were received. A kin to this could be Morbius, which was an incredibly poorly rated movie that became subject to memes and a lot of comedy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067c59b-8983-4acc-972a-1ecd852ded57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 3 (5)\n",
    "\n",
    "![](../figures/wordcloud_comedy.png)\n",
    "![](../figures/wordcloud_drama.png)\n",
    "![](../figures/wordcloud_horror.png)\n",
    "\n",
    "Looking at the word clouds of the top words (by TFIDF) across some of the most popular genres, there appears to be a major consensus in the most common terms used. Words like \"film\", \"movie\", and \"story\" appear to be some of the largest in all. But there are also a few interesting differences. For comedy, we can see that \"love\" is a more prominent word, and that \"fun\" and \"laugh\" were also included. For drama, \"characters\" and \"people\" are much more frequent than the other genres, and \"plot\" is slightly larger. For horror, we see key additions, like \"blood\", but also see less emphasis on words like \"plot\" and \"characters\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e25c6e-2624-4899-829e-e7d60c878685",
   "metadata": {},
   "source": [
    "# Interpretation (4)\n",
    "\n",
    "Describe something interesting about your corpus that you discovered during the process of completing this assignment.\n",
    "\n",
    "At a minumum, use 250 words, but you may use more. You may also add images if you'd like.\n",
    "\n",
    "Throughout the project and analyzing this corpus of movie review, I was able to gain interesting in notable insights in the text and differences across genre, time, and rating.\n",
    "\n",
    "One interesting discovery was the distribution of sentiment across genres. Genres like Comedy, Action, and Drama exhibited much more neutral average sentiments, with broader ranges, suggesting a wider variety of emotional responses from audiences. Though this is likely due to the higher presence of these genres in the data, it makes sense due to their popularity in modern film. In contrast, more specific genres such as Game-Show and Western had more narrow sentiment distributions, possibly due to their more niche appeal. This indicates that more popular genres tend to evoke a wider spectrum of emotions, while niche genres elicit more consistent reactions.\n",
    "\n",
    "Another interesting observation came from the topic modeling results using PCA and LDA. When visualizing the PCA components, it was clear that genres like Comedy and Action had a more dispersed distribution, pointing to a greater diversity in themes within those genres. On the other hand, the more niche genre reviews were more concentrated in the feature space, having higher mean document weights, reflecting a more focused set of thematic elements.\n",
    "\n",
    "In addition, analyzing TFIDF revealed some key linguistic differences across genres. For instance, words like \"laugh\", \"fun\", and \"love\" dominated in Comedy, while genres like Drama saw terms like \"characters\" and \"story\" appear more frequently and horor with \"blood\". These findings reinforced how the language used in movie reviews reflects the genreâ€™s emotional and thematic focus.\n",
    "\n",
    "Overall, this project revealed how sentiment and thematic content vary across genres and the reviews corresponding to them, highlighting how the language in such reviews mirrors the expectations and characteristics of different movie categories over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
